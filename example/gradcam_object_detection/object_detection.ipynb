{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install foxai yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Example of running XAI on YOLOv5 on Object Detection task.\"\"\"\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from typing import Tuple\n",
    "from custom_models.ssd.ssd_object_detector import SSDObjectDetector\n",
    "from custom_models.yolov5.model import WrapperYOLOv5ObjectDetectionModel\n",
    "from custom_models.yolov5.yolo_object_detector import (\n",
    "    YOLOv5ObjectDetector,\n",
    "    get_yolo_layer,\n",
    ")\n",
    "from PIL import Image\n",
    "from torchvision.models._meta import _COCO_CATEGORIES\n",
    "from torchvision.models.detection import SSD300_VGG16_Weights\n",
    "\n",
    "from foxai.explainer.computer_vision.algorithm.gradcam import (\n",
    "    LayerGradCAMObjectDetectionExplainer,\n",
    "    ObjectDetectionOutput,\n",
    ")\n",
    "from foxai.visualizer import object_detection_visualization\n",
    "\n",
    "\n",
    "def main(model_name: str, img_path: str, output_dir: str, layer_name: str, img_size: Tuple[int, int]):\n",
    "    \"\"\"Run YOLO_v5 XAI and save results.\"\"\"\n",
    "\n",
    "    image = Image.open(img_path)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    preprocessed_image = YOLOv5ObjectDetector.preprocessing(\n",
    "        img=np.asarray(image),\n",
    "        new_shape=img_size,\n",
    "        change_original_ratio=True,\n",
    "    ).to(device)\n",
    "\n",
    "    preprocessed_image_shape = preprocessed_image.shape[-2:]\n",
    "\n",
    "    if \"ssd\" in model_name:\n",
    "        weights = SSD300_VGG16_Weights.COCO_V1\n",
    "        model = (\n",
    "            torchvision.models.detection.ssd300_vgg16(weights=weights, pretrained=True)\n",
    "            .eval()\n",
    "            .to(device)\n",
    "        )\n",
    "        preprocess = weights.transforms()\n",
    "        model.detections_per_img = 10\n",
    "        input_image = preprocess(preprocessed_image).to(device)\n",
    "\n",
    "        model_wrapper = SSDObjectDetector(model=model, class_names=_COCO_CATEGORIES)\n",
    "        target_layer = model_wrapper.model.backbone.features[-1]\n",
    "    else:\n",
    "        assert preprocessed_image.shape[-1] % 32 == 0, f\"Image shape have to be divisible by 32. Current shape is {preprocessed_image.shape}\"\n",
    "        assert preprocessed_image.shape[-2] % 32 == 0, f\"Image shape have to be divisible by 32. Current shape is {preprocessed_image.shape}\"\n",
    "        model = torch.hub.load(\"ultralytics/yolov5\", model_name, pretrained=True)\n",
    "        names = model.model.names\n",
    "        wrapper_model = WrapperYOLOv5ObjectDetectionModel(\n",
    "            model=model.model.model,\n",
    "            device=device,\n",
    "        )\n",
    "        model_wrapper = YOLOv5ObjectDetector(\n",
    "            model=wrapper_model,\n",
    "            img_size=preprocessed_image_shape,\n",
    "            names=names,\n",
    "        )\n",
    "        target_layer = get_yolo_layer(\n",
    "            model=model_wrapper,\n",
    "            layer_name=layer_name,\n",
    "        )\n",
    "\n",
    "        input_image = preprocessed_image\n",
    "\n",
    "    saliency_method = LayerGradCAMObjectDetectionExplainer(\n",
    "        model=model_wrapper,\n",
    "        target_layer=target_layer,\n",
    "    )\n",
    "    outputs: ObjectDetectionOutput = saliency_method(input_img=input_image)\n",
    "    final_image = object_detection_visualization(\n",
    "        detections=outputs,\n",
    "        input_image=input_image,\n",
    "    )\n",
    "    img_name = f\"{output_dir}/yolo_gradcam.png\"\n",
    "    output_path = f\"./{img_name}\"\n",
    "    os.makedirs(\".\", exist_ok=True)\n",
    "    print(f\"[INFO] Saving the final image at {output_path}\")\n",
    "    cv2.imwrite(output_path, final_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"yolov5s\"\n",
    "img_path = \"../images/zidane.jpg\"\n",
    "output_dir = \"./\"\n",
    "layer_name = \"model_23_cv3_act\"\n",
    "resize_to_img_size = (640, 640)\n",
    "\n",
    "main(\n",
    "    model_name=model_name,\n",
    "    img_path=img_path,\n",
    "    output_dir=output_dir,\n",
    "    layer_name=layer_name,\n",
    "    img_size=resize_to_img_size,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
