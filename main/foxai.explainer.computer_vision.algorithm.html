<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>foxai.explainer.computer_vision.algorithm package &mdash; FoXAI  documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="foxai.explainer.computer_vision.object_detection package" href="foxai.explainer.computer_vision.object_detection.html" />
    <link rel="prev" title="foxai.explainer.computer_vision package" href="foxai.explainer.computer_vision.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            FoXAI
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting started:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="install.html">Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">foxai</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="foxai.html">foxai package</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="foxai.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="foxai.callbacks.html">foxai.callbacks package</a></li>
<li class="toctree-l4"><a class="reference internal" href="foxai.cli.html">foxai.cli package</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="foxai.explainer.html">foxai.explainer package</a></li>
<li class="toctree-l4"><a class="reference internal" href="foxai.metrics.html">foxai.metrics package</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="foxai.html#submodules">Submodules</a></li>
<li class="toctree-l3"><a class="reference internal" href="foxai.html#module-foxai.array_utils">foxai.array_utils module</a></li>
<li class="toctree-l3"><a class="reference internal" href="foxai.html#module-foxai.context_manager">foxai.context_manager module</a></li>
<li class="toctree-l3"><a class="reference internal" href="foxai.html#module-foxai.logger">foxai.logger module</a></li>
<li class="toctree-l3"><a class="reference internal" href="foxai.html#module-foxai.visualizer">foxai.visualizer module</a></li>
<li class="toctree-l3"><a class="reference internal" href="foxai.html#module-foxai">Module contents</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">FoXAI</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="modules.html">foxai</a></li>
          <li class="breadcrumb-item"><a href="foxai.html">foxai package</a></li>
          <li class="breadcrumb-item"><a href="foxai.explainer.html">foxai.explainer package</a></li>
          <li class="breadcrumb-item"><a href="foxai.explainer.computer_vision.html">foxai.explainer.computer_vision package</a></li>
      <li class="breadcrumb-item active">foxai.explainer.computer_vision.algorithm package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/foxai.explainer.computer_vision.algorithm.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="foxai-explainer-computer-vision-algorithm-package">
<h1>foxai.explainer.computer_vision.algorithm package<a class="headerlink" href="#foxai-explainer-computer-vision-algorithm-package" title="Permalink to this heading"></a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this heading"></a></h2>
</section>
<section id="module-foxai.explainer.computer_vision.algorithm.conductance">
<span id="foxai-explainer-computer-vision-algorithm-conductance-module"></span><h2>foxai.explainer.computer_vision.algorithm.conductance module<a class="headerlink" href="#module-foxai.explainer.computer_vision.algorithm.conductance" title="Permalink to this heading"></a></h2>
<p>File with Conductance algorithm explainer classes.</p>
<p>Based on <a class="reference external" href="https://github.com/pytorch/captum/blob/master/captum/attr/_core/layer/layer_conductance.py">https://github.com/pytorch/captum/blob/master/captum/attr/_core/layer/layer_conductance.py</a>.</p>
<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.conductance.LayerConductanceCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.conductance.</span></span><span class="sig-name descname"><span class="pre">LayerConductanceCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/conductance.html#LayerConductanceCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.conductance.LayerConductanceCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="foxai.explainer.html#foxai.explainer.base_explainer.Explainer" title="foxai.explainer.base_explainer.Explainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Explainer</span></code></a></p>
<p>Layer Conductance algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.conductance.LayerConductanceCVExplainer.calculate_features">
<span class="sig-name descname"><span class="pre">calculate_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_label_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'gausslegendre'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">internal_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attribute_to_layer_input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/conductance.html#LayerConductanceCVExplainer.calculate_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.conductance.LayerConductanceCVExplainer.calculate_features" title="Permalink to this definition"></a></dt>
<dd><p>Generate model’s attributes with Layer Conductance algorithm explainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>input_data</strong> – Input for which layer
conductance is computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.</p></li>
<li><p><strong>pred_label_idx</strong> – <p>Output indices for
which gradients are computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>a single integer or a tensor containing a single</dt><dd><p>integer, which is applied to all input examples</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>a list of integers or a 1D tensor, with length matching</dt><dd><p>the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>A single tuple, which contains #output_dims - 1</dt><dd><p>elements. This target index is applied to all examples.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>A list of tuples with length equal to the number of</dt><dd><p>examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><strong>baselines</strong> – <p>Baselines define the starting point from which integral
is computed and can be provided as:</p>
<ul>
<li><dl class="simple">
<dt>a single tensor, if inputs is a single tensor, with</dt><dd><p>exactly the same dimensions as inputs or the first
dimension is one and the remaining dimensions match
with inputs.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>a single scalar, if inputs is a single tensor, which will</dt><dd><p>be broadcasted for each input value in input tensor.</p>
</dd>
</dl>
</li>
</ul>
<p>In the cases when <cite>baselines</cite> is not provided, we internally
use zero scalar corresponding to each input tensor.
Default: None</p>
</p></li>
<li><p><strong>additional_forward_args</strong> – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
For a tensor, the first dimension of the tensor must
correspond to the number of examples. It will be repeated
for each of <cite>n_steps</cite> along the integrated path.
For all other types, the given argument is used for
all forward evaluations.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><strong>n_steps</strong> – The number of steps used by the approximation
method. Default: 50.</p></li>
<li><p><strong>method</strong> – Method for approximating the integral,
one of <cite>riemann_right</cite>, <cite>riemann_left</cite>, <cite>riemann_middle</cite>,
<cite>riemann_trapezoid</cite> or <cite>gausslegendre</cite>.
Default: <cite>gausslegendre</cite> if no method is provided.</p></li>
<li><p><strong>internal_batch_size</strong> – Divides total #steps * #examples
data points into chunks of size at most internal_batch_size,
which are computed (forward / backward passes)
sequentially. internal_batch_size must be at least equal to
2 * #examples.
For DataParallel models, each batch is split among the
available devices, so evaluations on each available
device contain internal_batch_size / num_devices examples.
If internal_batch_size is None, then all evaluations are
processed in one batch.
Default: None</p></li>
<li><p><strong>attribute_to_layer_input</strong> – Indicates whether to
compute the attribution with respect to the layer input
or output. If <cite>attribute_to_layer_input</cite> is set to True
then the attributions will be computed with respect to
layer inputs, otherwise it will be computed with respect
to layer outputs.
Note that currently it is assumed that either the input
or the output of internal layer, depending on whether we
attribute to the input or output, is a single tensor.
Support for multiple tensors will be added later.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Conductance of each neuron in given layer input or
output. Attributions will always be the same size as
the input or output of the given layer, depending on
whether we attribute to the inputs or outputs
of the layer which is decided by the input flag
<cite>attribute_to_layer_input</cite>.
Attributions are returned in a tuple if
the layer inputs / outputs contain multiple tensors,
otherwise a single tensor is returned.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ValueError</strong> – if model does not contain conv layers.</p></li>
<li><p><strong>RuntimeError</strong> – if attribution has shape (0)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.conductance.LayerConductanceCVExplainer.create_explainer">
<span class="sig-name descname"><span class="pre">create_explainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">LayerConductance</span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/conductance.html#LayerConductanceCVExplainer.create_explainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.conductance.LayerConductanceCVExplainer.create_explainer" title="Permalink to this definition"></a></dt>
<dd><p>Create explainer object.</p>
<dl class="simple">
<dt>model: The forward function of the model or any</dt><dd><p>modification of it.</p>
</dd>
<dt>layer: Layer for which attributions are computed.</dt><dd><p>Output size of attribute matches this layer’s input or
output dimensions, depending on whether we attribute to
the inputs or outputs of the layer, corresponding to
attribution of each neuron in the input or output of
this layer.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Explainer object.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-foxai.explainer.computer_vision.algorithm.deconv">
<span id="foxai-explainer-computer-vision-algorithm-deconv-module"></span><h2>foxai.explainer.computer_vision.algorithm.deconv module<a class="headerlink" href="#module-foxai.explainer.computer_vision.algorithm.deconv" title="Permalink to this heading"></a></h2>
<p>File with Deconvolution algorithm explainer classes.</p>
<p>Based on <a class="reference external" href="https://github.com/pytorch/captum/blob/master/captum/attr/_core/guided_backprop_deconvnet.py">https://github.com/pytorch/captum/blob/master/captum/attr/_core/guided_backprop_deconvnet.py</a>.</p>
<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.deconv.BaseDeconvolutionCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.deconv.</span></span><span class="sig-name descname"><span class="pre">BaseDeconvolutionCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/deconv.html#BaseDeconvolutionCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.deconv.BaseDeconvolutionCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="foxai.explainer.html#foxai.explainer.base_explainer.Explainer" title="foxai.explainer.base_explainer.Explainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Explainer</span></code></a></p>
<p>Base Deconvolution algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.deconv.BaseDeconvolutionCVExplainer.calculate_features">
<span class="sig-name descname"><span class="pre">calculate_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_label_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/deconv.html#BaseDeconvolutionCVExplainer.calculate_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.deconv.BaseDeconvolutionCVExplainer.calculate_features" title="Permalink to this definition"></a></dt>
<dd><p>Generate model’s attributes with Deconvolution algorithm explainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>inputs</strong> – Input for which
attributions are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.</p></li>
<li><p><strong>pred_label_idx</strong> – <p>Output indices for
which gradients are computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>a single integer or a tensor containing a single</dt><dd><p>integer, which is applied to all input examples</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>a list of integers or a 1D tensor, with length matching</dt><dd><p>the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>A single tuple, which contains #output_dims - 1</dt><dd><p>elements. This target index is applied to all examples.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>A list of tuples with length equal to the number of</dt><dd><p>examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><strong>additional_forward_args</strong> – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a tuple
containing multiple additional arguments including tensors
or any arbitrary python types. These arguments are provided to
forward_func in order, following the arguments in inputs.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The deconvolution attributions with respect to each
input feature. Attributions will always
be the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>RuntimeError</strong> – if attribution has shape (0).</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.deconv.BaseDeconvolutionCVExplainer.create_explainer">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">create_explainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Deconvolution</span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/deconv.html#BaseDeconvolutionCVExplainer.create_explainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.deconv.BaseDeconvolutionCVExplainer.create_explainer" title="Permalink to this definition"></a></dt>
<dd><p>Create explainer object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> – The forward function of the model or any
modification of it.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Explainer object.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.deconv.DeconvolutionCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.deconv.</span></span><span class="sig-name descname"><span class="pre">DeconvolutionCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/deconv.html#DeconvolutionCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.deconv.DeconvolutionCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#foxai.explainer.computer_vision.algorithm.deconv.BaseDeconvolutionCVExplainer" title="foxai.explainer.computer_vision.algorithm.deconv.BaseDeconvolutionCVExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseDeconvolutionCVExplainer</span></code></a></p>
<p>Base Deconvolution algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.deconv.DeconvolutionCVExplainer.create_explainer">
<span class="sig-name descname"><span class="pre">create_explainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Deconvolution</span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/deconv.html#DeconvolutionCVExplainer.create_explainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.deconv.DeconvolutionCVExplainer.create_explainer" title="Permalink to this definition"></a></dt>
<dd><p>Create explainer object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> – The forward function of the model or any
modification of it.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Explainer object.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-foxai.explainer.computer_vision.algorithm.deeplift">
<span id="foxai-explainer-computer-vision-algorithm-deeplift-module"></span><h2>foxai.explainer.computer_vision.algorithm.deeplift module<a class="headerlink" href="#module-foxai.explainer.computer_vision.algorithm.deeplift" title="Permalink to this heading"></a></h2>
<p>File with DeepLIFT algorithm explainer classes.</p>
<p>Based on <a class="reference external" href="https://github.com/pytorch/captum/blob/master/captum/attr/_core/deep_lift.py">https://github.com/pytorch/captum/blob/master/captum/attr/_core/deep_lift.py</a>
and <a class="reference external" href="https://github.com/pytorch/captum/blob/master/captum/attr/_core/layer/layer_deep_lift.py">https://github.com/pytorch/captum/blob/master/captum/attr/_core/layer/layer_deep_lift.py</a>.</p>
<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.deeplift.BaseDeepLIFTCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.deeplift.</span></span><span class="sig-name descname"><span class="pre">BaseDeepLIFTCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/deeplift.html#BaseDeepLIFTCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.deeplift.BaseDeepLIFTCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="foxai.explainer.html#foxai.explainer.base_explainer.Explainer" title="foxai.explainer.base_explainer.Explainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Explainer</span></code></a></p>
<p>Base DeepLIFT algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.deeplift.BaseDeepLIFTCVExplainer.calculate_features">
<span class="sig-name descname"><span class="pre">calculate_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_label_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_attribution_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attribute_to_layer_input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/deeplift.html#BaseDeepLIFTCVExplainer.calculate_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.deeplift.BaseDeepLIFTCVExplainer.calculate_features" title="Permalink to this definition"></a></dt>
<dd><p>Generate model’s attributes with DeepLIFT algorithm explainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>input_data</strong> – Input for which
attributions are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.</p></li>
<li><p><strong>pred_label_idx</strong> – <p>Output indices for
which gradients are computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>a single integer or a tensor containing a single</dt><dd><p>integer, which is applied to all input examples</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>a list of integers or a 1D tensor, with length matching</dt><dd><p>the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>A single tuple, which contains #output_dims - 1</dt><dd><p>elements. This target index is applied to all examples.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>A list of tuples with length equal to the number of</dt><dd><p>examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><strong>baselines</strong> – <p>Baselines define reference samples that are compared with
the inputs. In order to assign attribution scores DeepLift
computes the differences between the inputs/outputs and
corresponding references.
Baselines can be provided as:</p>
<ul>
<li><dl class="simple">
<dt>a single tensor, if inputs is a single tensor, with</dt><dd><p>exactly the same dimensions as inputs or the first
dimension is one and the remaining dimensions match
with inputs.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>a single scalar, if inputs is a single tensor, which will</dt><dd><p>be broadcasted for each input value in input tensor.</p>
</dd>
</dl>
</li>
</ul>
<p>In the cases when <cite>baselines</cite> is not provided, we internally
use zero scalar corresponding to each input tensor.
Default: None</p>
</p></li>
<li><p><strong>additional_forward_args</strong> – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a tuple
containing multiple additional arguments including tensors
or any arbitrary python types. These arguments are provided to
forward_func in order, following the arguments in inputs.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><strong>custom_attribution_func</strong> – <p>A custom function for
computing final attribution scores. This function can take
at least one and at most three arguments with the
following signature:</p>
<ul>
<li><p>custom_attribution_func(multipliers)</p></li>
<li><p>custom_attribution_func(multipliers, inputs)</p></li>
<li><p>custom_attribution_func(multipliers, inputs, baselines)</p></li>
</ul>
<p>In case this function is not provided, we use the default
logic defined as: multipliers * (inputs - baselines)
It is assumed that all input arguments, <cite>multipliers</cite>,
<cite>inputs</cite> and <cite>baselines</cite> are provided in tuples of same
length. <cite>custom_attribution_func</cite> returns a tuple of
attribution tensors that have the same length as the
<cite>inputs</cite>.
Default: None</p>
</p></li>
<li><p><strong>attribute_to_layer_input</strong> – Indicates whether to
compute the attribution with respect to the layer input
or output. If <cite>attribute_to_layer_input</cite> is set to True
then the attributions will be computed with respect to
layer input, otherwise it will be computed with respect
to layer output.
Note that currently it is assumed that either the input
or the output of internal layer, depending on whether we
attribute to the input or output, is a single tensor.
Support for multiple tensors will be added later.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Attribution score computed based on DeepLift rescale rule with respect
to each input feature. Attributions will always be
the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>RuntimeError</strong> – if attribution has shape (0).</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.deeplift.BaseDeepLIFTCVExplainer.create_explainer">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">create_explainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multiply_by_inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">DeepLift</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">LayerDeepLift</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/deeplift.html#BaseDeepLIFTCVExplainer.create_explainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.deeplift.BaseDeepLIFTCVExplainer.create_explainer" title="Permalink to this definition"></a></dt>
<dd><p>Create explainer object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>multiply_by_inputs</strong> – <p>Indicates whether to factor
model inputs’ multiplier in the final attribution scores.
In the literature this is also known as local vs global
attribution. If inputs’ multiplier isn’t factored in
then that type of attribution method is also called local
attribution. If it is, then that type of attribution
method is called global.
More detailed can be found here:
<a class="reference external" href="https://arxiv.org/abs/1711.06104">https://arxiv.org/abs/1711.06104</a></p>
<p>In case of DeepLift, if <cite>multiply_by_inputs</cite>
is set to True, final sensitivity scores
are being multiplied by (inputs - baselines).
This flag applies only if <cite>custom_attribution_func</cite> is
set to None.</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Explainer object.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.deeplift.DeepLIFTCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.deeplift.</span></span><span class="sig-name descname"><span class="pre">DeepLIFTCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/deeplift.html#DeepLIFTCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.deeplift.DeepLIFTCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#foxai.explainer.computer_vision.algorithm.deeplift.BaseDeepLIFTCVExplainer" title="foxai.explainer.computer_vision.algorithm.deeplift.BaseDeepLIFTCVExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseDeepLIFTCVExplainer</span></code></a></p>
<p>DeepLIFTC algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.deeplift.DeepLIFTCVExplainer.create_explainer">
<span class="sig-name descname"><span class="pre">create_explainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multiply_by_inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-10</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">DeepLift</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">LayerDeepLift</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/deeplift.html#DeepLIFTCVExplainer.create_explainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.deeplift.DeepLIFTCVExplainer.create_explainer" title="Permalink to this definition"></a></dt>
<dd><p>Create explainer object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>multiply_by_inputs</strong> – <p>Indicates whether to factor
model inputs’ multiplier in the final attribution scores.
In the literature this is also known as local vs global
attribution. If inputs’ multiplier isn’t factored in
then that type of attribution method is also called local
attribution. If it is, then that type of attribution
method is called global.
More detailed can be found here:
<a class="reference external" href="https://arxiv.org/abs/1711.06104">https://arxiv.org/abs/1711.06104</a></p>
<p>In case of DeepLift, if <cite>multiply_by_inputs</cite>
is set to True, final sensitivity scores
are being multiplied by (inputs - baselines).
This flag applies only if <cite>custom_attribution_func</cite> is
set to None.</p>
</p></li>
<li><p><strong>eps</strong> – A value at which to consider output/input change
significant when computing the gradients for non-linear layers.
This is useful to adjust, depending on your model’s bit depth,
to avoid numerical issues during the gradient computation.
Default: 1e-10</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Explainer object.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.deeplift.LayerDeepLIFTCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.deeplift.</span></span><span class="sig-name descname"><span class="pre">LayerDeepLIFTCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/deeplift.html#LayerDeepLIFTCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.deeplift.LayerDeepLIFTCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#foxai.explainer.computer_vision.algorithm.deeplift.BaseDeepLIFTCVExplainer" title="foxai.explainer.computer_vision.algorithm.deeplift.BaseDeepLIFTCVExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseDeepLIFTCVExplainer</span></code></a></p>
<p>Layer DeepLIFT algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.deeplift.LayerDeepLIFTCVExplainer.create_explainer">
<span class="sig-name descname"><span class="pre">create_explainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multiply_by_inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Module</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">DeepLift</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">LayerDeepLift</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/deeplift.html#LayerDeepLIFTCVExplainer.create_explainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.deeplift.LayerDeepLIFTCVExplainer.create_explainer" title="Permalink to this definition"></a></dt>
<dd><p>Create explainer object.</p>
<p>Uses parameter <cite>layer</cite> from <cite>kwargs</cite>. If not provided function will call
<cite>get_last_conv_model_layer</cite> function to obtain last <cite>torch.nn.Conv2d</cite> layer
from provided model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>layer</strong> – Layer for which attributions are computed.
Output size of attribute matches this layer’s input or
output dimensions, depending on whether we attribute to
the inputs or outputs of the layer, corresponding to
attribution of each neuron in the input or output of
this layer.
Default: None</p></li>
<li><p><strong>multiply_by_inputs</strong> – <p>Indicates whether to factor
model inputs’ multiplier in the final attribution scores.
In the literature this is also known as local vs global
attribution. If inputs’ multiplier isn’t factored in
then that type of attribution method is also called local
attribution. If it is, then that type of attribution
method is called global.
More detailed can be found here:
<a class="reference external" href="https://arxiv.org/abs/1711.06104">https://arxiv.org/abs/1711.06104</a></p>
<p>In case of DeepLift, if <cite>multiply_by_inputs</cite>
is set to True, final sensitivity scores
are being multiplied by (inputs - baselines).
This flag applies only if <cite>custom_attribution_func</cite> is
set to None.</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Explainer object.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong> – if model does not contain conv layers.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-foxai.explainer.computer_vision.algorithm.deeplift_shap">
<span id="foxai-explainer-computer-vision-algorithm-deeplift-shap-module"></span><h2>foxai.explainer.computer_vision.algorithm.deeplift_shap module<a class="headerlink" href="#module-foxai.explainer.computer_vision.algorithm.deeplift_shap" title="Permalink to this heading"></a></h2>
<p>File with DeepLIFT SHAP algorithm explainer classes.</p>
<p>Based on <a class="reference external" href="https://github.com/pytorch/captum/blob/master/captum/attr/_core/deep_lift.py">https://github.com/pytorch/captum/blob/master/captum/attr/_core/deep_lift.py</a>
and <a class="reference external" href="https://github.com/pytorch/captum/blob/master/captum/attr/_core/layer/layer_deep_lift.py">https://github.com/pytorch/captum/blob/master/captum/attr/_core/layer/layer_deep_lift.py</a>.</p>
<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.deeplift_shap.BaseDeepLIFTSHAPCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.deeplift_shap.</span></span><span class="sig-name descname"><span class="pre">BaseDeepLIFTSHAPCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/deeplift_shap.html#BaseDeepLIFTSHAPCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.deeplift_shap.BaseDeepLIFTSHAPCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="foxai.explainer.html#foxai.explainer.base_explainer.Explainer" title="foxai.explainer.base_explainer.Explainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Explainer</span></code></a></p>
<p>Base DeepLIFT SHAP algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.deeplift_shap.BaseDeepLIFTSHAPCVExplainer.calculate_features">
<span class="sig-name descname"><span class="pre">calculate_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_label_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_attribution_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attribute_to_layer_input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/deeplift_shap.html#BaseDeepLIFTSHAPCVExplainer.calculate_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.deeplift_shap.BaseDeepLIFTSHAPCVExplainer.calculate_features" title="Permalink to this definition"></a></dt>
<dd><p>Generate model’s attributes with DeepLIFT SHAP algorithm explainer.</p>
<p>Under the hood this method is calling <cite>DeepLiftShap.attribute</cite> function and
therefore uses the same arguments. Source of parameters documentation:
<a class="reference external" href="https://github.com/pytorch/captum/blob/master/captum/attr/_core/deep_lift.py">https://github.com/pytorch/captum/blob/master/captum/attr/_core/deep_lift.py</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>input_data</strong> – Input for which
attributions are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.</p></li>
<li><p><strong>pred_label_idx</strong> – <p>Output indices for
which gradients are computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>a single integer or a tensor containing a single</dt><dd><p>integer, which is applied to all input examples</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>a list of integers or a 1D tensor, with length matching</dt><dd><p>the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>A single tuple, which contains #output_dims - 1</dt><dd><p>elements. This target index is applied to all examples.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>A list of tuples with length equal to the number of</dt><dd><p>examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><strong>baselines</strong> – <p>Baselines define reference samples that are compared with
the inputs. In order to assign attribution scores DeepLift
computes the differences between the inputs/outputs and
corresponding references.
Baselines can be provided as:</p>
<ul>
<li><dl class="simple">
<dt>a single tensor, if inputs is a single tensor, with</dt><dd><p>exactly the same dimensions as inputs or the first
dimension is one and the remaining dimensions match
with inputs.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>a single scalar, if inputs is a single tensor, which will</dt><dd><p>be broadcasted for each input value in input tensor.</p>
</dd>
</dl>
</li>
</ul>
<p>In the cases when <cite>baselines</cite> is not provided, we internally
use zero scalar corresponding to each input tensor.
Default: None</p>
</p></li>
<li><p><strong>additional_forward_args</strong> – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a tuple
containing multiple additional arguments including tensors
or any arbitrary python types. These arguments are provided to
forward_func in order, following the arguments in inputs.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><strong>custom_attribution_func</strong> – <p>A custom function for
computing final attribution scores. This function can take
at least one and at most three arguments with the
following signature:</p>
<ul>
<li><p>custom_attribution_func(multipliers)</p></li>
<li><p>custom_attribution_func(multipliers, inputs)</p></li>
<li><p>custom_attribution_func(multipliers, inputs, baselines)</p></li>
</ul>
<p>In case this function is not provided, we use the default
logic defined as: multipliers * (inputs - baselines)
It is assumed that all input arguments, <cite>multipliers</cite>,
<cite>inputs</cite> and <cite>baselines</cite> are provided in tuples of same
length. <cite>custom_attribution_func</cite> returns a tuple of
attribution tensors that have the same length as the
<cite>inputs</cite>.
Default: None</p>
</p></li>
<li><p><strong>attribute_to_layer_input</strong> – Argument present only for <cite>LayerDeepLiftShap</cite>.
Indicates whether to compute the attributions with respect
to the layer input or output. If <cite>attribute_to_layer_input</cite>
is set to True then the attributions will be computed with
respect to layer inputs, otherwise it will be computed with
respect to layer outputs.
Note that currently it assumes that both the inputs and
outputs of internal layers are single tensors.
Support for multiple tensors will be added later.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Attribution score computed based on DeepLift rescale rule with respect
to each input feature. Attributions will always be
the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>RuntimeError</strong> – if attribution has shape (0).</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.deeplift_shap.BaseDeepLIFTSHAPCVExplainer.create_explainer">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">create_explainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multiply_by_inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">DeepLiftShap</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">LayerDeepLiftShap</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/deeplift_shap.html#BaseDeepLIFTSHAPCVExplainer.create_explainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.deeplift_shap.BaseDeepLIFTSHAPCVExplainer.create_explainer" title="Permalink to this definition"></a></dt>
<dd><p>Create explainer object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>multiply_by_inputs</strong> – <p>Indicates whether to factor
model inputs’ multiplier in the final attribution scores.
In the literature this is also known as local vs global
attribution. If inputs’ multiplier isn’t factored in
then that type of attribution method is also called local
attribution. If it is, then that type of attribution
method is called global.
More detailed can be found here:
<a class="reference external" href="https://arxiv.org/abs/1711.06104">https://arxiv.org/abs/1711.06104</a></p>
<p>In case of DeepLift, if <cite>multiply_by_inputs</cite>
is set to True, final sensitivity scores
are being multiplied by (inputs - baselines).
This flag applies only if <cite>custom_attribution_func</cite> is
set to None.</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Explainer object.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.deeplift_shap.DeepLIFTSHAPCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.deeplift_shap.</span></span><span class="sig-name descname"><span class="pre">DeepLIFTSHAPCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/deeplift_shap.html#DeepLIFTSHAPCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.deeplift_shap.DeepLIFTSHAPCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#foxai.explainer.computer_vision.algorithm.deeplift_shap.BaseDeepLIFTSHAPCVExplainer" title="foxai.explainer.computer_vision.algorithm.deeplift_shap.BaseDeepLIFTSHAPCVExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseDeepLIFTSHAPCVExplainer</span></code></a></p>
<p>DeepLIFTC SHAP algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.deeplift_shap.DeepLIFTSHAPCVExplainer.create_explainer">
<span class="sig-name descname"><span class="pre">create_explainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multiply_by_inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">DeepLiftShap</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">LayerDeepLiftShap</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/deeplift_shap.html#DeepLIFTSHAPCVExplainer.create_explainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.deeplift_shap.DeepLIFTSHAPCVExplainer.create_explainer" title="Permalink to this definition"></a></dt>
<dd><p>Create explainer object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>multiply_by_inputs</strong> – <p>Indicates whether to factor
model inputs’ multiplier in the final attribution scores.
In the literature this is also known as local vs global
attribution. If inputs’ multiplier isn’t factored in
then that type of attribution method is also called local
attribution. If it is, then that type of attribution
method is called global.
More detailed can be found here:
<a class="reference external" href="https://arxiv.org/abs/1711.06104">https://arxiv.org/abs/1711.06104</a></p>
<p>In case of LayerDeepLiftShap, if <cite>multiply_by_inputs</cite>
is set to True, final sensitivity scores are being
multiplied by
layer activations for inputs - layer activations for baselines
This flag applies only if <cite>custom_attribution_func</cite> is
set to None.</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Explainer object.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.deeplift_shap.LayerDeepLIFTSHAPCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.deeplift_shap.</span></span><span class="sig-name descname"><span class="pre">LayerDeepLIFTSHAPCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/deeplift_shap.html#LayerDeepLIFTSHAPCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.deeplift_shap.LayerDeepLIFTSHAPCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#foxai.explainer.computer_vision.algorithm.deeplift_shap.BaseDeepLIFTSHAPCVExplainer" title="foxai.explainer.computer_vision.algorithm.deeplift_shap.BaseDeepLIFTSHAPCVExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseDeepLIFTSHAPCVExplainer</span></code></a></p>
<p>Layer DeepLIFT SHAP algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.deeplift_shap.LayerDeepLIFTSHAPCVExplainer.create_explainer">
<span class="sig-name descname"><span class="pre">create_explainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multiply_by_inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Module</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">DeepLiftShap</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">LayerDeepLiftShap</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/deeplift_shap.html#LayerDeepLIFTSHAPCVExplainer.create_explainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.deeplift_shap.LayerDeepLIFTSHAPCVExplainer.create_explainer" title="Permalink to this definition"></a></dt>
<dd><p>Create explainer object.</p>
<p>Uses parameter <cite>layer</cite> from <cite>kwargs</cite>. If not provided function will call
<cite>get_last_conv_model_layer</cite> function to obtain last <cite>torch.nn.Conv2d</cite> layer
from provided model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>layer</strong> – Layer for which attributions are computed.
Output size of attribute matches this layer’s input or
output dimensions, depending on whether we attribute to
the inputs or outputs of the layer, corresponding to
attribution of each neuron in the input or output of
this layer.
Default: None</p></li>
<li><p><strong>multiply_by_inputs</strong> – <p>Indicates whether to factor
model inputs’ multiplier in the final attribution scores.
In the literature this is also known as local vs global
attribution. If inputs’ multiplier isn’t factored in
then that type of attribution method is also called local
attribution. If it is, then that type of attribution
method is called global.
More detailed can be found here:
<a class="reference external" href="https://arxiv.org/abs/1711.06104">https://arxiv.org/abs/1711.06104</a></p>
<p>In case of LayerDeepLiftShap, if <cite>multiply_by_inputs</cite>
is set to True, final sensitivity scores are being
multiplied by
layer activations for inputs - layer activations for baselines
This flag applies only if <cite>custom_attribution_func</cite> is
set to None.</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Explainer object.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong> – if model does not contain conv layers.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-foxai.explainer.computer_vision.algorithm.gradcam">
<span id="foxai-explainer-computer-vision-algorithm-gradcam-module"></span><h2>foxai.explainer.computer_vision.algorithm.gradcam module<a class="headerlink" href="#module-foxai.explainer.computer_vision.algorithm.gradcam" title="Permalink to this heading"></a></h2>
<p>File with GradCAM algorithm explainer classes.</p>
<p>Based on <a class="reference external" href="https://github.com/pytorch/captum/blob/master/captum/attr/_core/guided_grad_cam.py">https://github.com/pytorch/captum/blob/master/captum/attr/_core/guided_grad_cam.py</a>
and <a class="reference external" href="https://github.com/pytorch/captum/blob/master/captum/attr/_core/layer/grad_cam.py">https://github.com/pytorch/captum/blob/master/captum/attr/_core/layer/grad_cam.py</a>.</p>
<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.gradcam.BaseGradCAMCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.gradcam.</span></span><span class="sig-name descname"><span class="pre">BaseGradCAMCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/gradcam.html#BaseGradCAMCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.gradcam.BaseGradCAMCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="foxai.explainer.html#foxai.explainer.base_explainer.Explainer" title="foxai.explainer.base_explainer.Explainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Explainer</span></code></a></p>
<p>Base GradCAM algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.gradcam.BaseGradCAMCVExplainer.calculate_features">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">calculate_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_label_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attribute_to_layer_input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/gradcam.html#BaseGradCAMCVExplainer.calculate_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.gradcam.BaseGradCAMCVExplainer.calculate_features" title="Permalink to this definition"></a></dt>
<dd><p>Generate features image with GradCAM algorithm explainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>input_data</strong> – Input for which attributions
are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.</p></li>
<li><p><strong>pred_label_idx</strong> – <p>Output indices for
which gradients are computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>a single integer or a tensor containing a single</dt><dd><p>integer, which is applied to all input examples</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>a list of integers or a 1D tensor, with length matching</dt><dd><p>the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>A single tuple, which contains #output_dims - 1</dt><dd><p>elements. This target index is applied to all examples.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>A list of tuples with length equal to the number of</dt><dd><p>examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><strong>additional_forward_args</strong> – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><strong>attribute_to_layer_input</strong> – Indicates whether to
compute the attribution with respect to the layer input
or output in <cite>LayerGradCam</cite>.
If <cite>attribute_to_layer_input</cite> is set to True
then the attributions will be computed with respect to
layer inputs, otherwise it will be computed with respect
to layer outputs.
Note that currently it is assumed that either the input
or the output of internal layer, depending on whether we
attribute to the input or output, is a single tensor.
Support for multiple tensors will be added later.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Element-wise product of (upsampled) GradCAM
and/or Guided Backprop attributions.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.
Attributions will be the same size as the provided inputs,
with each value providing the attribution of the
corresponding input index.
If the GradCAM attributions cannot be upsampled to the shape
of a given input tensor, None is returned in the corresponding
index position.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.gradcam.BaseGradCAMCVExplainer.create_explainer">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">create_explainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">GuidedGradCam</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#foxai.explainer.computer_vision.algorithm.gradcam.LayerBaseGradCAM" title="foxai.explainer.computer_vision.algorithm.gradcam.LayerBaseGradCAM"><span class="pre">LayerBaseGradCAM</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/gradcam.html#BaseGradCAMCVExplainer.create_explainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.gradcam.BaseGradCAMCVExplainer.create_explainer" title="Permalink to this definition"></a></dt>
<dd><p>Create explainer object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>layer</strong> – Layer for which attributions are computed.
Output size of attribute matches this layer’s input or
output dimensions, depending on whether we attribute to
the inputs or outputs of the layer, corresponding to
attribution of each neuron in the input or output of
this layer.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Explainer object.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.gradcam.GuidedGradCAMCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.gradcam.</span></span><span class="sig-name descname"><span class="pre">GuidedGradCAMCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/gradcam.html#GuidedGradCAMCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.gradcam.GuidedGradCAMCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#foxai.explainer.computer_vision.algorithm.gradcam.BaseGradCAMCVExplainer" title="foxai.explainer.computer_vision.algorithm.gradcam.BaseGradCAMCVExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseGradCAMCVExplainer</span></code></a></p>
<p>GuidedGradCAM algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.gradcam.GuidedGradCAMCVExplainer.calculate_features">
<span class="sig-name descname"><span class="pre">calculate_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_label_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attribute_to_layer_input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interpolate_mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'nearest'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/gradcam.html#GuidedGradCAMCVExplainer.calculate_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.gradcam.GuidedGradCAMCVExplainer.calculate_features" title="Permalink to this definition"></a></dt>
<dd><p>Generate model’s attributes with GradCAM algorithm explainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>input_data</strong> – Input for which attributions
are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.</p></li>
<li><p><strong>pred_label_idx</strong> – <p>Output indices for
which gradients are computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>a single integer or a tensor containing a single</dt><dd><p>integer, which is applied to all input examples</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>a list of integers or a 1D tensor, with length matching</dt><dd><p>the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>A single tuple, which contains #output_dims - 1</dt><dd><p>elements. This target index is applied to all examples.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>A list of tuples with length equal to the number of</dt><dd><p>examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><strong>additional_forward_args</strong> – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><strong>interpolate_mode</strong> – Method for interpolation, which
must be a valid input interpolation mode for
torch.nn.functional. These methods are
“nearest”, “area”, “linear” (3D-only), “bilinear”
(4D-only), “bicubic” (4D-only), “trilinear” (5D-only)
based on the number of dimensions of the chosen layer
output (which must also match the number of
dimensions for the input tensor). Note that
the original GradCAM paper uses “bilinear”
interpolation, but we default to “nearest” for
applicability to any of 3D, 4D or 5D tensors.
Default: “nearest”</p></li>
<li><p><strong>attribute_to_layer_input</strong> – Indicates whether to
compute the attribution with respect to the layer input
or output in <cite>LayerGradCam</cite>.
If <cite>attribute_to_layer_input</cite> is set to True
then the attributions will be computed with respect to
layer inputs, otherwise it will be computed with respect
to layer outputs.
Note that currently it is assumed that either the input
or the output of internal layer, depending on whether we
attribute to the input or output, is a single tensor.
Support for multiple tensors will be added later.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Element-wise product of (upsampled) GradCAM
and/or Guided Backprop attributions.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.
Attributions will be the same size as the provided inputs,
with each value providing the attribution of the
corresponding input index.
If the GradCAM attributions cannot be upsampled to the shape
of a given input tensor, None is returned in the corresponding
index position.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ValueError</strong> – if model does not contain conv layers.</p></li>
<li><p><strong>RuntimeError</strong> – if attributions has shape (0)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.gradcam.GuidedGradCAMCVExplainer.create_explainer">
<span class="sig-name descname"><span class="pre">create_explainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">GuidedGradCam</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#foxai.explainer.computer_vision.algorithm.gradcam.LayerBaseGradCAM" title="foxai.explainer.computer_vision.algorithm.gradcam.LayerBaseGradCAM"><span class="pre">LayerBaseGradCAM</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/gradcam.html#GuidedGradCAMCVExplainer.create_explainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.gradcam.GuidedGradCAMCVExplainer.create_explainer" title="Permalink to this definition"></a></dt>
<dd><p>Create explainer object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>layer</strong> – Layer for which attributions are computed.
Output size of attribute matches this layer’s input or
output dimensions, depending on whether we attribute to
the inputs or outputs of the layer, corresponding to
attribution of each neuron in the input or output of
this layer.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Explainer object.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.gradcam.LayerBaseGradCAM">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.gradcam.</span></span><span class="sig-name descname"><span class="pre">LayerBaseGradCAM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_layer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/gradcam.html#LayerBaseGradCAM"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.gradcam.LayerBaseGradCAM" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Layer GradCAM for object detection task.</p>
<dl class="py property">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.gradcam.LayerBaseGradCAM.activations">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">activations</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.gradcam.LayerBaseGradCAM.activations" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.gradcam.LayerBaseGradCAM.forward">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="foxai.explainer.computer_vision.object_detection.html#foxai.explainer.computer_vision.object_detection.types.ObjectDetectionOutput" title="foxai.explainer.computer_vision.object_detection.types.ObjectDetectionOutput"><span class="pre">ObjectDetectionOutput</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/gradcam.html#LayerBaseGradCAM.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.gradcam.LayerBaseGradCAM.forward" title="Permalink to this definition"></a></dt>
<dd><p>Forward pass of GradCAM aglorithm.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_img</strong> – Input image with shape of (B, C, H, W).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>ObjectDetectionOutput object for object detection and tensor with saliency
map for classification.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.gradcam.LayerBaseGradCAM.get_saliency_map">
<span class="sig-name descname"><span class="pre">get_saliency_map</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">height</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">width</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradients</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/gradcam.html#LayerBaseGradCAM.get_saliency_map"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.gradcam.LayerBaseGradCAM.get_saliency_map" title="Permalink to this definition"></a></dt>
<dd><p>Generate saliency map.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>height</strong> – Original image height.</p></li>
<li><p><strong>width</strong> – Original image width.</p></li>
<li><p><strong>gradients</strong> – Layer gradients.</p></li>
<li><p><strong>activations</strong> – Layer activations.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Saliency map.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.gradcam.LayerBaseGradCAM.gradients">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">gradients</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.gradcam.LayerBaseGradCAM.gradients" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.gradcam.LayerGradCAMCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.gradcam.</span></span><span class="sig-name descname"><span class="pre">LayerGradCAMCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/gradcam.html#LayerGradCAMCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.gradcam.LayerGradCAMCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#foxai.explainer.computer_vision.algorithm.gradcam.BaseGradCAMCVExplainer" title="foxai.explainer.computer_vision.algorithm.gradcam.BaseGradCAMCVExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseGradCAMCVExplainer</span></code></a></p>
<p>Layer GradCAM algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.gradcam.LayerGradCAMCVExplainer.calculate_features">
<span class="sig-name descname"><span class="pre">calculate_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_label_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attribute_to_layer_input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">relu_attributions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/gradcam.html#LayerGradCAMCVExplainer.calculate_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.gradcam.LayerGradCAMCVExplainer.calculate_features" title="Permalink to this definition"></a></dt>
<dd><p>Generate features image with GradCAM algorithm explainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>inputs_data</strong> – Input for which attributions
are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples, and if multiple input tensors
are provided, the examples must be aligned appropriately.</p></li>
<li><p><strong>pred_label_idx</strong> – <p>Output indices for
which gradients are computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>a single integer or a tensor containing a single</dt><dd><p>integer, which is applied to all input examples</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>a list of integers or a 1D tensor, with length matching</dt><dd><p>the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>A single tuple, which contains #output_dims - 1</dt><dd><p>elements. This target index is applied to all examples.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>A list of tuples with length equal to the number of</dt><dd><p>examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><strong>additional_forward_args</strong> – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><strong>attribute_to_layer_input</strong> – Indicates whether to
compute the attribution with respect to the layer input
or output in <cite>LayerGradCam</cite>.
If <cite>attribute_to_layer_input</cite> is set to True
then the attributions will be computed with respect to
layer inputs, otherwise it will be computed with respect
to layer outputs.
Note that currently it is assumed that either the input
or the output of internal layer, depending on whether we
attribute to the input or output, is a single tensor.
Support for multiple tensors will be added later.
Default: False</p></li>
<li><p><strong>relu_attributions</strong> – Indicates whether to
apply a ReLU operation on the final attribution,
returning only non-negative attributions. Setting this
flag to True matches the original GradCAM algorithm,
otherwise, by default, both positive and negative
attributions are returned.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Element-wise product of (upsampled) GradCAM
and/or Guided Backprop attributions.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.
Attributions will be the same size as the provided inputs,
with each value providing the attribution of the
corresponding input index.
If the GradCAM attributions cannot be upsampled to the shape
of a given input tensor, None is returned in the corresponding
index position.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ValueError</strong> – if model does not contain conv layers.</p></li>
<li><p><strong>RuntimeError</strong> – if attributions has shape (0)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.gradcam.LayerGradCAMCVExplainer.create_explainer">
<span class="sig-name descname"><span class="pre">create_explainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">GuidedGradCam</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#foxai.explainer.computer_vision.algorithm.gradcam.LayerBaseGradCAM" title="foxai.explainer.computer_vision.algorithm.gradcam.LayerBaseGradCAM"><span class="pre">LayerBaseGradCAM</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/gradcam.html#LayerGradCAMCVExplainer.create_explainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.gradcam.LayerGradCAMCVExplainer.create_explainer" title="Permalink to this definition"></a></dt>
<dd><p>Create explainer object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>layer</strong> – Layer for which attributions are computed.
Output size of attribute matches this layer’s input or
output dimensions, depending on whether we attribute to
the inputs or outputs of the layer, corresponding to
attribution of each neuron in the input or output of
this layer.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Explainer object.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.gradcam.LayerGradCAMObjectDetection">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.gradcam.</span></span><span class="sig-name descname"><span class="pre">LayerGradCAMObjectDetection</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_layer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/gradcam.html#LayerGradCAMObjectDetection"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.gradcam.LayerGradCAMObjectDetection" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#foxai.explainer.computer_vision.algorithm.gradcam.LayerBaseGradCAM" title="foxai.explainer.computer_vision.algorithm.gradcam.LayerBaseGradCAM"><code class="xref py py-class docutils literal notranslate"><span class="pre">LayerBaseGradCAM</span></code></a></p>
<p>Layer GradCAM for object detection task.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.gradcam.LayerGradCAMObjectDetection.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/gradcam.html#LayerGradCAMObjectDetection.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.gradcam.LayerGradCAMObjectDetection.forward" title="Permalink to this definition"></a></dt>
<dd><p>Forward pass of GradCAM aglorithm.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_img</strong> – Input image with shape of (B, C, H, W).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tensor with saliency map.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.gradcam.LayerGradCAMObjectDetectionExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.gradcam.</span></span><span class="sig-name descname"><span class="pre">LayerGradCAMObjectDetectionExplainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="foxai.explainer.computer_vision.object_detection.html#foxai.explainer.computer_vision.object_detection.base_object_detector.BaseObjectDetector" title="foxai.explainer.computer_vision.object_detection.base_object_detector.BaseObjectDetector"><span class="pre">BaseObjectDetector</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_layer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/gradcam.html#LayerGradCAMObjectDetectionExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.gradcam.LayerGradCAMObjectDetectionExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#foxai.explainer.computer_vision.algorithm.gradcam.LayerBaseGradCAM" title="foxai.explainer.computer_vision.algorithm.gradcam.LayerBaseGradCAM"><code class="xref py py-class docutils literal notranslate"><span class="pre">LayerBaseGradCAM</span></code></a></p>
<p>Layer GradCAM for object detection task.</p>
<p>Code based on <a class="reference external" href="https://github.com/pooya-mohammadi/yolov5-gradcam">https://github.com/pooya-mohammadi/yolov5-gradcam</a>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.gradcam.LayerGradCAMObjectDetectionExplainer.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="foxai.explainer.computer_vision.object_detection.html#foxai.explainer.computer_vision.object_detection.types.ObjectDetectionOutput" title="foxai.explainer.computer_vision.object_detection.types.ObjectDetectionOutput"><span class="pre">ObjectDetectionOutput</span></a></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/gradcam.html#LayerGradCAMObjectDetectionExplainer.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.gradcam.LayerGradCAMObjectDetectionExplainer.forward" title="Permalink to this definition"></a></dt>
<dd><p>Forward pass of GradCAM aglorithm.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_img</strong> – Input image with shape of (B, C, H, W).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>ObjectDetectionOutput object.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-foxai.explainer.computer_vision.algorithm.gradient_shap">
<span id="foxai-explainer-computer-vision-algorithm-gradient-shap-module"></span><h2>foxai.explainer.computer_vision.algorithm.gradient_shap module<a class="headerlink" href="#module-foxai.explainer.computer_vision.algorithm.gradient_shap" title="Permalink to this heading"></a></h2>
<p>File with Gradient SHAP algorithm explainer classes.</p>
<p>Based on <a class="reference external" href="https://github.com/pytorch/captum/blob/master/captum/attr/_core/gradient_shap.py">https://github.com/pytorch/captum/blob/master/captum/attr/_core/gradient_shap.py</a>
and <a class="reference external" href="https://github.com/pytorch/captum/blob/master/captum/attr/_core/layer/layer_gradient_shap.py">https://github.com/pytorch/captum/blob/master/captum/attr/_core/layer/layer_gradient_shap.py</a>.</p>
<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.gradient_shap.BaseGradientSHAPCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.gradient_shap.</span></span><span class="sig-name descname"><span class="pre">BaseGradientSHAPCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/gradient_shap.html#BaseGradientSHAPCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.gradient_shap.BaseGradientSHAPCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="foxai.explainer.html#foxai.explainer.base_explainer.Explainer" title="foxai.explainer.base_explainer.Explainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Explainer</span></code></a></p>
<p>Base Gradient SHAP algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.gradient_shap.BaseGradientSHAPCVExplainer.calculate_features">
<span class="sig-name descname"><span class="pre">calculate_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_label_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_samples</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stdevs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attribute_to_layer_input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/gradient_shap.html#BaseGradientSHAPCVExplainer.calculate_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.gradient_shap.BaseGradientSHAPCVExplainer.calculate_features" title="Permalink to this definition"></a></dt>
<dd><p>Generate model’s attributes with Gradient SHAP algorithm explainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>input_data</strong> – Input for which SHAP attribution
values are computed. If <cite>forward_func</cite> takes a single
tensor as input, a single input tensor should be provided.</p></li>
<li><p><strong>pred_label_idx</strong> – <p>Output indices for
which gradients are computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>a single integer or a tensor containing a single</dt><dd><p>integer, which is applied to all input examples</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>a list of integers or a 1D tensor, with length matching</dt><dd><p>the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>A single tuple, which contains #output_dims - 1</dt><dd><p>elements. This target index is applied to all examples.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>A list of tuples with length equal to the number of</dt><dd><p>examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><strong>baselines</strong> – <p>Baselines define the starting point from which expectation
is computed and can be provided as:</p>
<ul>
<li><dl class="simple">
<dt>a single tensor, if inputs is a single tensor, with</dt><dd><p>the first dimension equal to the number of examples
in the baselines’ distribution. The remaining dimensions
must match with input tensor’s dimension starting from
the second dimension.</p>
</dd>
</dl>
</li>
</ul>
<p>It is recommended that the number of samples in the baselines’
tensors is larger than one.</p>
</p></li>
<li><p><strong>n_samples</strong> – The number of randomly generated examples
per sample in the input batch. Random examples are
generated by adding gaussian random noise to each sample.
Default: <cite>5</cite> if <cite>n_samples</cite> is not provided.</p></li>
<li><p><strong>stdevs</strong> – The standard deviation
of gaussian noise with zero mean that is added to each
input in the batch. If <cite>stdevs</cite> is a single float value
then that same value is used for all inputs. If it is
a tuple, then it must have the same length as the inputs
tuple. In this case, each stdev value in the stdevs tuple
corresponds to the input with the same index in the inputs
tuple.
Default: 0.0</p></li>
<li><p><strong>additional_forward_args</strong> – <p>If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It can contain a tuple of ND tensors or
any arbitrary python type of any shape.
In case of the ND tensor the first dimension of the
tensor must correspond to the batch size. It will be
repeated for each <cite>n_steps</cite> for each randomly generated
input sample.</p>
<p>Note that the gradients are not computed with respect
to these arguments.
Default: None</p>
</p></li>
<li><p><strong>attribute_to_layer_input</strong> (<em>bool</em><em>, </em><em>optional</em>) – <p>Indicates whether to
compute the attribution with respect to the layer input
or output. If <cite>attribute_to_layer_input</cite> is set to True
then the attributions will be computed with respect to
layer input, otherwise it will be computed with respect
to layer output.</p>
<p>Note that currently it is assumed that either the input
or the output of internal layer, depending on whether we
attribute to the input or output, is a single tensor.
Support for multiple tensors will be added later.
Default: False</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Attribution score computed based on GradientSHAP with respect
to each input feature. Attributions will always be
the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>RuntimeError</strong> – if attribution has shape (0).</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.gradient_shap.BaseGradientSHAPCVExplainer.create_explainer">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">create_explainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multiply_by_inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">GradientShap</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">LayerGradientShap</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/gradient_shap.html#BaseGradientSHAPCVExplainer.create_explainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.gradient_shap.BaseGradientSHAPCVExplainer.create_explainer" title="Permalink to this definition"></a></dt>
<dd><p>Create explainer object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>multiply_by_inputs</strong> – <p>Indicates whether to factor
model inputs’ multiplier in the final attribution scores.
In the literature this is also known as local vs global
attribution. If inputs’ multiplier isn’t factored in
then this type of attribution method is also called local
attribution. If it is, then that type of attribution
method is called global.
More detailed can be found here:
<a class="reference external" href="https://arxiv.org/abs/1711.06104">https://arxiv.org/abs/1711.06104</a></p>
<p>In case of gradient shap, if <cite>multiply_by_inputs</cite>
is set to True, the sensitivity scores of scaled inputs
are being multiplied by (inputs - baselines).</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Explainer object.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.gradient_shap.GradientSHAPCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.gradient_shap.</span></span><span class="sig-name descname"><span class="pre">GradientSHAPCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/gradient_shap.html#GradientSHAPCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.gradient_shap.GradientSHAPCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#foxai.explainer.computer_vision.algorithm.gradient_shap.BaseGradientSHAPCVExplainer" title="foxai.explainer.computer_vision.algorithm.gradient_shap.BaseGradientSHAPCVExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseGradientSHAPCVExplainer</span></code></a></p>
<p>Gradient SHAP algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.gradient_shap.GradientSHAPCVExplainer.create_explainer">
<span class="sig-name descname"><span class="pre">create_explainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multiply_by_inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">GradientShap</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">LayerGradientShap</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/gradient_shap.html#GradientSHAPCVExplainer.create_explainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.gradient_shap.GradientSHAPCVExplainer.create_explainer" title="Permalink to this definition"></a></dt>
<dd><p>Create explainer object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>multiply_by_inputs</strong> – <p>Indicates whether to factor
model inputs’ multiplier in the final attribution scores.
In the literature this is also known as local vs global
attribution. If inputs’ multiplier isn’t factored in
then this type of attribution method is also called local
attribution. If it is, then that type of attribution
method is called global.
More detailed can be found here:
<a class="reference external" href="https://arxiv.org/abs/1711.06104">https://arxiv.org/abs/1711.06104</a></p>
<p>In case of gradient shap, if <cite>multiply_by_inputs</cite>
is set to True, the sensitivity scores of scaled inputs
are being multiplied by (inputs - baselines).</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Explainer object.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.gradient_shap.LayerGradientSHAPCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.gradient_shap.</span></span><span class="sig-name descname"><span class="pre">LayerGradientSHAPCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/gradient_shap.html#LayerGradientSHAPCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.gradient_shap.LayerGradientSHAPCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#foxai.explainer.computer_vision.algorithm.gradient_shap.BaseGradientSHAPCVExplainer" title="foxai.explainer.computer_vision.algorithm.gradient_shap.BaseGradientSHAPCVExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseGradientSHAPCVExplainer</span></code></a></p>
<p>Layer Gradient SHAP algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.gradient_shap.LayerGradientSHAPCVExplainer.create_explainer">
<span class="sig-name descname"><span class="pre">create_explainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multiply_by_inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Module</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">GradientShap</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">LayerGradientShap</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/gradient_shap.html#LayerGradientSHAPCVExplainer.create_explainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.gradient_shap.LayerGradientSHAPCVExplainer.create_explainer" title="Permalink to this definition"></a></dt>
<dd><p>Create explainer object.</p>
<p>Uses parameter <cite>layer</cite> from <cite>kwargs</cite>. If not provided function will call
<cite>get_last_conv_model_layer</cite> function to obtain last <cite>torch.nn.Conv2d</cite> layer
from provided model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>layer</strong> – Layer for which attributions are computed.
Output size of attribute matches this layer’s input or
output dimensions, depending on whether we attribute to
the inputs or outputs of the layer, corresponding to
attribution of each neuron in the input or output of
this layer.
Default: None</p></li>
<li><p><strong>multiply_by_inputs</strong> – <p>Indicates whether to factor
model inputs’ multiplier in the final attribution scores.
In the literature this is also known as local vs global
attribution. If inputs’ multiplier isn’t factored in
then this type of attribution method is also called local
attribution. If it is, then that type of attribution
method is called global.
More detailed can be found here:
<a class="reference external" href="https://arxiv.org/abs/1711.06104">https://arxiv.org/abs/1711.06104</a></p>
<p>In case of layer gradient shap, if <cite>multiply_by_inputs</cite>
is set to True, the sensitivity scores for scaled inputs
are being multiplied by
layer activations for inputs - layer activations for baselines.</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Explainer object.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong> – if model does not contain conv layers.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-foxai.explainer.computer_vision.algorithm.guided_backprop">
<span id="foxai-explainer-computer-vision-algorithm-guided-backprop-module"></span><h2>foxai.explainer.computer_vision.algorithm.guided_backprop module<a class="headerlink" href="#module-foxai.explainer.computer_vision.algorithm.guided_backprop" title="Permalink to this heading"></a></h2>
<p>File with Guided Backpropagation algorithm explainer class.</p>
<p>Based on <a class="reference external" href="https://github.com/pytorch/captum/blob/master/captum/attr/_core/guided_backprop_deconvnet.py">https://github.com/pytorch/captum/blob/master/captum/attr/_core/guided_backprop_deconvnet.py</a>.</p>
<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.guided_backprop.BaseGuidedBackpropCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.guided_backprop.</span></span><span class="sig-name descname"><span class="pre">BaseGuidedBackpropCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/guided_backprop.html#BaseGuidedBackpropCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.guided_backprop.BaseGuidedBackpropCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="foxai.explainer.html#foxai.explainer.base_explainer.Explainer" title="foxai.explainer.base_explainer.Explainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Explainer</span></code></a></p>
<p>Base Guided Backpropagation algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.guided_backprop.BaseGuidedBackpropCVExplainer.calculate_features">
<span class="sig-name descname"><span class="pre">calculate_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_label_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/guided_backprop.html#BaseGuidedBackpropCVExplainer.calculate_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.guided_backprop.BaseGuidedBackpropCVExplainer.calculate_features" title="Permalink to this definition"></a></dt>
<dd><p>Generate model’s attributes with Guided Backpropagation algorithm explainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>input_data</strong> – Input for which
attributions are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples (aka batch size), and if
multiple input tensors are provided, the examples must
be aligned appropriately.</p></li>
<li><p><strong>pred_label_idx</strong> – <p>Output indices for
which gradients are computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>a single integer or a tensor containing a single</dt><dd><p>integer, which is applied to all input examples</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>a list of integers or a 1D tensor, with length matching</dt><dd><p>the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>A single tuple, which contains #output_dims - 1</dt><dd><p>elements. This target index is applied to all examples.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>A list of tuples with length equal to the number of</dt><dd><p>examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><strong>additional_forward_args</strong> – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a tuple
containing multiple additional arguments including tensors
or any arbitrary python types. These arguments are provided to
forward_func in order, following the arguments in inputs.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The guided backprop gradients with respect to each
input feature. Attributions will always
be the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>RuntimeError</strong> – if attribution has shape (0).</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.guided_backprop.BaseGuidedBackpropCVExplainer.create_explainer">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">create_explainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">GuidedBackprop</span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/guided_backprop.html#BaseGuidedBackpropCVExplainer.create_explainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.guided_backprop.BaseGuidedBackpropCVExplainer.create_explainer" title="Permalink to this definition"></a></dt>
<dd><p>Create explainer object.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Explainer object.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.guided_backprop.GuidedBackpropCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.guided_backprop.</span></span><span class="sig-name descname"><span class="pre">GuidedBackpropCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/guided_backprop.html#GuidedBackpropCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.guided_backprop.GuidedBackpropCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#foxai.explainer.computer_vision.algorithm.guided_backprop.BaseGuidedBackpropCVExplainer" title="foxai.explainer.computer_vision.algorithm.guided_backprop.BaseGuidedBackpropCVExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseGuidedBackpropCVExplainer</span></code></a></p>
<p>Guided Backpropagation algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.guided_backprop.GuidedBackpropCVExplainer.create_explainer">
<span class="sig-name descname"><span class="pre">create_explainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">GuidedBackprop</span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/guided_backprop.html#GuidedBackpropCVExplainer.create_explainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.guided_backprop.GuidedBackpropCVExplainer.create_explainer" title="Permalink to this definition"></a></dt>
<dd><p>Create explainer object.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Explainer object.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-foxai.explainer.computer_vision.algorithm.input_x_gradient">
<span id="foxai-explainer-computer-vision-algorithm-input-x-gradient-module"></span><h2>foxai.explainer.computer_vision.algorithm.input_x_gradient module<a class="headerlink" href="#module-foxai.explainer.computer_vision.algorithm.input_x_gradient" title="Permalink to this heading"></a></h2>
<p>File with Input X Gradient algorithm explainer classes.</p>
<p>Based on <a class="reference external" href="https://github.com/pytorch/captum/blob/master/captum/attr/_core/input_x_gradient.py">https://github.com/pytorch/captum/blob/master/captum/attr/_core/input_x_gradient.py</a>
and <a class="reference external" href="https://github.com/pytorch/captum/blob/master/captum/attr/_core/layer/layer_gradient_x_activation.py">https://github.com/pytorch/captum/blob/master/captum/attr/_core/layer/layer_gradient_x_activation.py</a>.</p>
<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.input_x_gradient.BaseInputXGradientSHAPCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.input_x_gradient.</span></span><span class="sig-name descname"><span class="pre">BaseInputXGradientSHAPCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/input_x_gradient.html#BaseInputXGradientSHAPCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.input_x_gradient.BaseInputXGradientSHAPCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="foxai.explainer.html#foxai.explainer.base_explainer.Explainer" title="foxai.explainer.base_explainer.Explainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Explainer</span></code></a></p>
<p>Base Input X Gradient algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.input_x_gradient.BaseInputXGradientSHAPCVExplainer.calculate_features">
<span class="sig-name descname"><span class="pre">calculate_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_label_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attribute_to_layer_input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/input_x_gradient.html#BaseInputXGradientSHAPCVExplainer.calculate_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.input_x_gradient.BaseInputXGradientSHAPCVExplainer.calculate_features" title="Permalink to this definition"></a></dt>
<dd><p>Generate model’s attributes with Input X Gradient algorithm explainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>input_data</strong> – Input for which
attributions are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.</p></li>
<li><p><strong>pred_label_idx</strong> – <p>Output indices for
which gradients are computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>a single integer or a tensor containing a single</dt><dd><p>integer, which is applied to all input examples</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>a list of integers or a 1D tensor, with length matching</dt><dd><p>the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>A single tuple, which contains #output_dims - 1</dt><dd><p>elements. This target index is applied to all examples.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>A list of tuples with length equal to the number of</dt><dd><p>examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><strong>additional_forward_args</strong> – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a tuple
containing multiple additional arguments including tensors
or any arbitrary python types. These arguments are provided to
forward_func in order following the arguments in inputs.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><strong>attribute_to_layer_input</strong> – Indicates whether to
compute the attribution with respect to the layer input
or output. If <cite>attribute_to_layer_input</cite> is set to True
then the attributions will be computed with respect to
layer input, otherwise it will be computed with respect
to layer output.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The input x gradient with respect to each input feature or gradient
and activation for each neuron in given layer output. Attributions
will always be the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>RuntimeError</strong> – if attribution has shape (0).</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.input_x_gradient.BaseInputXGradientSHAPCVExplainer.create_explainer">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">create_explainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">InputXGradient</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">LayerGradientXActivation</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/input_x_gradient.html#BaseInputXGradientSHAPCVExplainer.create_explainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.input_x_gradient.BaseInputXGradientSHAPCVExplainer.create_explainer" title="Permalink to this definition"></a></dt>
<dd><p>Create explainer object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> – The forward function of the model or any
modification of it.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Explainer object.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.input_x_gradient.InputXGradientCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.input_x_gradient.</span></span><span class="sig-name descname"><span class="pre">InputXGradientCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/input_x_gradient.html#InputXGradientCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.input_x_gradient.InputXGradientCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#foxai.explainer.computer_vision.algorithm.input_x_gradient.BaseInputXGradientSHAPCVExplainer" title="foxai.explainer.computer_vision.algorithm.input_x_gradient.BaseInputXGradientSHAPCVExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseInputXGradientSHAPCVExplainer</span></code></a></p>
<p>Input X Gradient algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.input_x_gradient.InputXGradientCVExplainer.create_explainer">
<span class="sig-name descname"><span class="pre">create_explainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">InputXGradient</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">LayerGradientXActivation</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/input_x_gradient.html#InputXGradientCVExplainer.create_explainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.input_x_gradient.InputXGradientCVExplainer.create_explainer" title="Permalink to this definition"></a></dt>
<dd><p>Create explainer object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> – The forward function of the model or any
modification of it.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Explainer object.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.input_x_gradient.LayerInputXGradientCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.input_x_gradient.</span></span><span class="sig-name descname"><span class="pre">LayerInputXGradientCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/input_x_gradient.html#LayerInputXGradientCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.input_x_gradient.LayerInputXGradientCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#foxai.explainer.computer_vision.algorithm.input_x_gradient.BaseInputXGradientSHAPCVExplainer" title="foxai.explainer.computer_vision.algorithm.input_x_gradient.BaseInputXGradientSHAPCVExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseInputXGradientSHAPCVExplainer</span></code></a></p>
<p>Layer Input X Gradient algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.input_x_gradient.LayerInputXGradientCVExplainer.create_explainer">
<span class="sig-name descname"><span class="pre">create_explainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Module</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multiply_by_inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">InputXGradient</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">LayerGradientXActivation</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/input_x_gradient.html#LayerInputXGradientCVExplainer.create_explainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.input_x_gradient.LayerInputXGradientCVExplainer.create_explainer" title="Permalink to this definition"></a></dt>
<dd><p>Create explainer object.</p>
<p>Uses parameter <cite>layer</cite> from <cite>kwargs</cite>. If not provided function will call
<cite>get_last_conv_model_layer</cite> function to obtain last <cite>torch.nn.Conv2d</cite> layer
from provided model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>layer</strong> – Layer for which attributions are computed.
Output size of attribute matches this layer’s input or
output dimensions, depending on whether we attribute to
the inputs or outputs of the layer, corresponding to
attribution of each neuron in the input or output of
this layer.
Default: None</p></li>
<li><p><strong>multiply_by_inputs</strong> – <p>Indicates whether to factor
model inputs’ multiplier in the final attribution scores.
In the literature this is also known as local vs global
attribution. If inputs’ multiplier isn’t factored in,
then this type of attribution method is also called local
attribution. If it is, then that type of attribution
method is called global.
More detailed can be found here:
<a class="reference external" href="https://arxiv.org/abs/1711.06104">https://arxiv.org/abs/1711.06104</a></p>
<p>In case of layer gradient x activation, if <cite>multiply_by_inputs</cite>
is set to True, final sensitivity scores are being multiplied by
layer activations for inputs.</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Explainer object.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong> – if model does not contain conv layers.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-foxai.explainer.computer_vision.algorithm.integrated_gradients">
<span id="foxai-explainer-computer-vision-algorithm-integrated-gradients-module"></span><h2>foxai.explainer.computer_vision.algorithm.integrated_gradients module<a class="headerlink" href="#module-foxai.explainer.computer_vision.algorithm.integrated_gradients" title="Permalink to this heading"></a></h2>
<p>File with Integrated Gradients algorithm explainer classes.</p>
<p>Based on <a class="reference external" href="https://github.com/pytorch/captum/blob/master/captum/attr/_core/integrated_gradients.py">https://github.com/pytorch/captum/blob/master/captum/attr/_core/integrated_gradients.py</a>
and <a class="reference external" href="https://github.com/pytorch/captum/blob/master/captum/attr/_core/layer/layer_integrated_gradients.py">https://github.com/pytorch/captum/blob/master/captum/attr/_core/layer/layer_integrated_gradients.py</a>.</p>
<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.integrated_gradients.BaseIntegratedGradientsCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.integrated_gradients.</span></span><span class="sig-name descname"><span class="pre">BaseIntegratedGradientsCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/integrated_gradients.html#BaseIntegratedGradientsCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.integrated_gradients.BaseIntegratedGradientsCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="foxai.explainer.html#foxai.explainer.base_explainer.Explainer" title="foxai.explainer.base_explainer.Explainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Explainer</span></code></a></p>
<p>Base Integrated Gradients algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.integrated_gradients.BaseIntegratedGradientsCVExplainer.calculate_features">
<span class="sig-name descname"><span class="pre">calculate_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_label_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'gausslegendre'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">internal_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attribute_to_layer_input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/integrated_gradients.html#BaseIntegratedGradientsCVExplainer.calculate_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.integrated_gradients.BaseIntegratedGradientsCVExplainer.calculate_features" title="Permalink to this definition"></a></dt>
<dd><p>Generate model’s attributes with Integrated Gradients algorithm explainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>input_data</strong> – Input for which layer integrated
gradients are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.</p></li>
<li><p><strong>pred_label_idx</strong> – <p>Output indices for
which gradients are computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>a single integer or a tensor containing a single</dt><dd><p>integer, which is applied to all input examples</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>a list of integers or a 1D tensor, with length matching</dt><dd><p>the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>A single tuple, which contains #output_dims - 1</dt><dd><p>elements. This target index is applied to all examples.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>A list of tuples with length equal to the number of</dt><dd><p>examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><strong>baselines</strong> – <p>Baselines define the starting point from which integral
is computed and can be provided as:</p>
<ul>
<li><dl class="simple">
<dt>a single tensor, if inputs is a single tensor, with</dt><dd><p>exactly the same dimensions as inputs or the first
dimension is one and the remaining dimensions match
with inputs.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>a single scalar, if inputs is a single tensor, which will</dt><dd><p>be broadcasted for each input value in input tensor.</p>
</dd>
</dl>
</li>
</ul>
<p>In the cases when <cite>baselines</cite> is not provided, we internally
use zero scalar corresponding to each input tensor.
Default: None</p>
</p></li>
<li><p><strong>additional_forward_args</strong> – <p>If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.</p>
<p>For a tensor, the first dimension of the tensor must
correspond to the number of examples. It will be
repeated for each of <cite>n_steps</cite> along the integrated
path. For all other types, the given argument is used
for all forward evaluations.</p>
<p>Note that attributions are not computed with respect
to these arguments.
Default: None</p>
</p></li>
<li><p><strong>n_steps</strong> – The number of steps used by the approximation
method. Default: 50.</p></li>
<li><p><strong>method</strong> – Method for approximating the integral,
one of <cite>riemann_right</cite>, <cite>riemann_left</cite>, <cite>riemann_middle</cite>,
<cite>riemann_trapezoid</cite> or <cite>gausslegendre</cite>.
Default: <cite>gausslegendre</cite> if no method is provided.</p></li>
<li><p><strong>internal_batch_size</strong> – <p>Divides total #steps * #examples
data points into chunks of size at most internal_batch_size,
which are computed (forward / backward passes)
sequentially. internal_batch_size must be at least equal to
#examples.</p>
<p>For DataParallel models, each batch is split among the
available devices, so evaluations on each available
device contain internal_batch_size / num_devices examples.
If internal_batch_size is None, then all evaluations are
processed in one batch.
Default: None</p>
</p></li>
<li><p><strong>attribute_to_layer_input</strong> – <p>Indicates whether to
compute the attribution with respect to the layer input
or output. If <cite>attribute_to_layer_input</cite> is set to True
then the attributions will be computed with respect to
layer input, otherwise it will be computed with respect
to layer output.</p>
<p>Note that currently it is assumed that either the input
or the output of internal layer, depending on whether we
attribute to the input or output, is a single tensor.
Support for multiple tensors will be added later.
Default: False</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>Integrated gradients with respect to <cite>layer</cite>’s inputs
or outputs. Attributions will always be the same size and
dimensionality as the input or output of the given layer,
depending on whether we attribute to the inputs or outputs
of the layer which is decided by the input flag
<cite>attribute_to_layer_input</cite>.</p>
<p>For a single layer, attributions are returned in a tuple if
the layer inputs / outputs contain multiple tensors,
otherwise a single tensor is returned.</p>
<p>For multiple layers, attributions will always be
returned as a list. Each element in this list will be
equivalent to that of a single layer output, i.e. in the
case that one layer, in the given layers, inputs / outputs
multiple tensors: the corresponding output element will be
a tuple of tensors. The ordering of the outputs will be
the same order as the layers given in the constructor.</p>
</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>RuntimeError</strong> – if attribution has shape (0).</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.integrated_gradients.BaseIntegratedGradientsCVExplainer.create_explainer">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">create_explainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multiply_by_inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">IntegratedGradients</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">LayerIntegratedGradients</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/integrated_gradients.html#BaseIntegratedGradientsCVExplainer.create_explainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.integrated_gradients.BaseIntegratedGradientsCVExplainer.create_explainer" title="Permalink to this definition"></a></dt>
<dd><p>Create explainer object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>multiply_by_inputs</strong> – <p>Indicates whether to factor
model inputs’ multiplier in the final attribution scores.
In the literature this is also known as local vs global
attribution. If inputs’ multiplier isn’t factored in,
then that type of attribution method is also called local
attribution. If it is, then that type of attribution
method is called global.
More detailed can be found here:
<a class="reference external" href="https://arxiv.org/abs/1711.06104">https://arxiv.org/abs/1711.06104</a></p>
<p>In case of integrated gradients, if <cite>multiply_by_inputs</cite>
is set to True, final sensitivity scores are being multiplied by
(inputs - baselines).</p>
<p>In case of layer integrated gradients, if <cite>multiply_by_inputs</cite>
is set to True, final sensitivity scores are being multiplied by
layer activations for inputs - layer activations for baselines.</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Explainer object.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.integrated_gradients.IntegratedGradientsCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.integrated_gradients.</span></span><span class="sig-name descname"><span class="pre">IntegratedGradientsCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/integrated_gradients.html#IntegratedGradientsCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.integrated_gradients.IntegratedGradientsCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#foxai.explainer.computer_vision.algorithm.integrated_gradients.BaseIntegratedGradientsCVExplainer" title="foxai.explainer.computer_vision.algorithm.integrated_gradients.BaseIntegratedGradientsCVExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseIntegratedGradientsCVExplainer</span></code></a></p>
<p>Integrated Gradients algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.integrated_gradients.IntegratedGradientsCVExplainer.create_explainer">
<span class="sig-name descname"><span class="pre">create_explainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multiply_by_inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">IntegratedGradients</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">LayerIntegratedGradients</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/integrated_gradients.html#IntegratedGradientsCVExplainer.create_explainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.integrated_gradients.IntegratedGradientsCVExplainer.create_explainer" title="Permalink to this definition"></a></dt>
<dd><p>Create explainer object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>multiply_by_inputs</strong> – <p>Indicates whether to factor
model inputs’ multiplier in the final attribution scores.
In the literature this is also known as local vs global
attribution. If inputs’ multiplier isn’t factored in,
then that type of attribution method is also called local
attribution. If it is, then that type of attribution
method is called global.
More detailed can be found here:
<a class="reference external" href="https://arxiv.org/abs/1711.06104">https://arxiv.org/abs/1711.06104</a></p>
<p>In case of integrated gradients, if <cite>multiply_by_inputs</cite>
is set to True, final sensitivity scores are being multiplied by
(inputs - baselines).</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Explainer object.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.integrated_gradients.LayerIntegratedGradientsCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.integrated_gradients.</span></span><span class="sig-name descname"><span class="pre">LayerIntegratedGradientsCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/integrated_gradients.html#LayerIntegratedGradientsCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.integrated_gradients.LayerIntegratedGradientsCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#foxai.explainer.computer_vision.algorithm.integrated_gradients.BaseIntegratedGradientsCVExplainer" title="foxai.explainer.computer_vision.algorithm.integrated_gradients.BaseIntegratedGradientsCVExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseIntegratedGradientsCVExplainer</span></code></a></p>
<p>Layer Integrated Gradients algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.integrated_gradients.LayerIntegratedGradientsCVExplainer.create_explainer">
<span class="sig-name descname"><span class="pre">create_explainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multiply_by_inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Module</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">IntegratedGradients</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">LayerIntegratedGradients</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/integrated_gradients.html#LayerIntegratedGradientsCVExplainer.create_explainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.integrated_gradients.LayerIntegratedGradientsCVExplainer.create_explainer" title="Permalink to this definition"></a></dt>
<dd><p>Create explainer object.</p>
<p>Uses parameter <cite>layer</cite> from <cite>kwargs</cite>. If not provided function will call
<cite>get_last_conv_model_layer</cite> function to obtain last <cite>torch.nn.Conv2d</cite> layer
from provided model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>layer</strong> – Layer for which attributions are computed.
Output size of attribute matches this layer’s input or
output dimensions, depending on whether we attribute to
the inputs or outputs of the layer, corresponding to
attribution of each neuron in the input or output of
this layer.
Default: None</p></li>
<li><p><strong>multiply_by_inputs</strong> – <p>Indicates whether to factor
model inputs’ multiplier in the final attribution scores.
In the literature this is also known as local vs global
attribution. If inputs’ multiplier isn’t factored in,
then that type of attribution method is also called local
attribution. If it is, then that type of attribution
method is called global.
More detailed can be found here:
<a class="reference external" href="https://arxiv.org/abs/1711.06104">https://arxiv.org/abs/1711.06104</a></p>
<p>In case of layer integrated gradients, if <cite>multiply_by_inputs</cite>
is set to True, final sensitivity scores are being multiplied by
layer activations for inputs - layer activations for baselines.</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Explainer object.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong> – if model does not contain conv layers.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-foxai.explainer.computer_vision.algorithm.lrp">
<span id="foxai-explainer-computer-vision-algorithm-lrp-module"></span><h2>foxai.explainer.computer_vision.algorithm.lrp module<a class="headerlink" href="#module-foxai.explainer.computer_vision.algorithm.lrp" title="Permalink to this heading"></a></h2>
<p>File with LRP algorithm explainer classes.</p>
<p>Based on <a class="reference external" href="https://github.com/pytorch/captum/blob/master/captum/attr/_core/lrp.py">https://github.com/pytorch/captum/blob/master/captum/attr/_core/lrp.py</a>
and <a class="reference external" href="https://github.com/pytorch/captum/blob/master/captum/attr/_core/layer/layer_lrp.py">https://github.com/pytorch/captum/blob/master/captum/attr/_core/layer/layer_lrp.py</a>.</p>
<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.lrp.BaseLRPCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.lrp.</span></span><span class="sig-name descname"><span class="pre">BaseLRPCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/lrp.html#BaseLRPCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.lrp.BaseLRPCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="foxai.explainer.html#foxai.explainer.base_explainer.Explainer" title="foxai.explainer.base_explainer.Explainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Explainer</span></code></a></p>
<p>Base LRP algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.lrp.BaseLRPCVExplainer.add_rules">
<span class="sig-name descname"><span class="pre">add_rules</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Module</span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/lrp.html#BaseLRPCVExplainer.add_rules"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.lrp.BaseLRPCVExplainer.add_rules" title="Permalink to this definition"></a></dt>
<dd><p>Add rules for the LRP explainer,
according to <a class="reference external" href="https://arxiv.org/pdf/1910.09840.pdf">https://arxiv.org/pdf/1910.09840.pdf</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> – The forward function of the model or any
modification of it.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Modified DNN object.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.lrp.BaseLRPCVExplainer.calculate_features">
<span class="sig-name descname"><span class="pre">calculate_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_label_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attribute_to_layer_input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/lrp.html#BaseLRPCVExplainer.calculate_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.lrp.BaseLRPCVExplainer.calculate_features" title="Permalink to this definition"></a></dt>
<dd><p>Generate model’s attributes with LRP algorithm explainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>input_data</strong> – Input for which relevance is
propagated. If forward_func takes a single
tensor as input, a single input tensor should be provided.</p></li>
<li><p><strong>pred_label_idx</strong> – <p>Output indices for
which gradients are computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>a single integer or a tensor containing a single</dt><dd><p>integer, which is applied to all input examples</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>a list of integers or a 1D tensor, with length matching</dt><dd><p>the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>A single tuple, which contains #output_dims - 1</dt><dd><p>elements. This target index is applied to all examples.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>A list of tuples with length equal to the number of</dt><dd><p>examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><strong>additional_forward_args</strong> – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a tuple
containing multiple additional arguments including tensors
or any arbitrary python types. These arguments are provided to
forward_func in order, following the arguments in inputs.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><strong>attribute_to_layer_input</strong> – Indicates whether to
compute the attribution with respect to the layer input
or output. If <cite>attribute_to_layer_input</cite> is set to True
then the attributions will be computed with respect to
layer input, otherwise it will be computed with respect
to layer output.</p></li>
<li><p><strong>verbose</strong> – Indicates whether information on application
of rules is printed during propagation.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Features matrix.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>RuntimeError</strong> – if attribution has shape (0).</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.lrp.BaseLRPCVExplainer.create_explainer">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">create_explainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">LRP</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">LayerLRP</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/lrp.html#BaseLRPCVExplainer.create_explainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.lrp.BaseLRPCVExplainer.create_explainer" title="Permalink to this definition"></a></dt>
<dd><p>Create explainer object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> – The forward function of the model or any
modification of it.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Explainer object.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.lrp.LRPCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.lrp.</span></span><span class="sig-name descname"><span class="pre">LRPCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/lrp.html#LRPCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.lrp.LRPCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#foxai.explainer.computer_vision.algorithm.lrp.BaseLRPCVExplainer" title="foxai.explainer.computer_vision.algorithm.lrp.BaseLRPCVExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseLRPCVExplainer</span></code></a></p>
<p>LRP algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.lrp.LRPCVExplainer.create_explainer">
<span class="sig-name descname"><span class="pre">create_explainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">LRP</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">LayerLRP</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/lrp.html#LRPCVExplainer.create_explainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.lrp.LRPCVExplainer.create_explainer" title="Permalink to this definition"></a></dt>
<dd><p>Create explainer object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> – The forward function of the model or any
modification of it.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Explainer object.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.lrp.LayerLRPCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.lrp.</span></span><span class="sig-name descname"><span class="pre">LayerLRPCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/lrp.html#LayerLRPCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.lrp.LayerLRPCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#foxai.explainer.computer_vision.algorithm.lrp.BaseLRPCVExplainer" title="foxai.explainer.computer_vision.algorithm.lrp.BaseLRPCVExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseLRPCVExplainer</span></code></a></p>
<p>Layer LRP algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.lrp.LayerLRPCVExplainer.create_explainer">
<span class="sig-name descname"><span class="pre">create_explainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Module</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">LRP</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">LayerLRP</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/lrp.html#LayerLRPCVExplainer.create_explainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.lrp.LayerLRPCVExplainer.create_explainer" title="Permalink to this definition"></a></dt>
<dd><p>Create explainer object.</p>
<p>Uses parameter <cite>layer</cite> from <cite>kwargs</cite>. If not provided function will call
<cite>get_last_conv_model_layer</cite> function to obtain last <cite>torch.nn.Conv2d</cite> layer
from provided model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>layer</strong> – Layer for which attributions are computed.
Output size of attribute matches this layer’s input or
output dimensions, depending on whether we attribute to
the inputs or outputs of the layer, corresponding to
attribution of each neuron in the input or output of
this layer.
Default: None</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Explainer object.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong> – if model does not contain conv layers.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-foxai.explainer.computer_vision.algorithm.noise_tunnel">
<span id="foxai-explainer-computer-vision-algorithm-noise-tunnel-module"></span><h2>foxai.explainer.computer_vision.algorithm.noise_tunnel module<a class="headerlink" href="#module-foxai.explainer.computer_vision.algorithm.noise_tunnel" title="Permalink to this heading"></a></h2>
<p>File with Noise Tunnel algorithm explainer classes.</p>
<p>Based on <a class="reference external" href="https://github.com/pytorch/captum/blob/master/captum/attr/_core/noise_tunnel.py">https://github.com/pytorch/captum/blob/master/captum/attr/_core/noise_tunnel.py</a>.</p>
<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.noise_tunnel.BaseNoiseTunnelCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.noise_tunnel.</span></span><span class="sig-name descname"><span class="pre">BaseNoiseTunnelCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/noise_tunnel.html#BaseNoiseTunnelCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.noise_tunnel.BaseNoiseTunnelCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="foxai.explainer.html#foxai.explainer.base_explainer.Explainer" title="foxai.explainer.base_explainer.Explainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Explainer</span></code></a></p>
<p>Base Noise Tunnel algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.noise_tunnel.BaseNoiseTunnelCVExplainer.calculate_features">
<span class="sig-name descname"><span class="pre">calculate_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_label_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nt_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'smoothgrad'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nt_samples</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nt_samples_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stdevs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">draw_baseline_from_distrib</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/noise_tunnel.html#BaseNoiseTunnelCVExplainer.calculate_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.noise_tunnel.BaseNoiseTunnelCVExplainer.calculate_features" title="Permalink to this definition"></a></dt>
<dd><p>Generate model’s attributes with Noise Tunnel algorithm explainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>input_data</strong> – Input for which integrated
gradients are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.</p></li>
<li><p><strong>pred_label_idx</strong> – <p>Output indices for
which gradients are computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>a single integer or a tensor containing a single</dt><dd><p>integer, which is applied to all input examples</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>a list of integers or a 1D tensor, with length matching</dt><dd><p>the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>A single tuple, which contains #output_dims - 1</dt><dd><p>elements. This target index is applied to all examples.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>A list of tuples with length equal to the number of</dt><dd><p>examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><strong>nt_type</strong> – Smoothing type of the attributions.
<cite>smoothgrad</cite>, <cite>smoothgrad_sq</cite> or <cite>vargrad</cite>
Default: <cite>smoothgrad</cite> if <cite>type</cite> is not provided.</p></li>
<li><p><strong>nt_samples</strong> – The number of randomly generated examples
per sample in the input batch. Random examples are
generated by adding gaussian random noise to each sample.
Default: <cite>5</cite> if <cite>nt_samples</cite> is not provided.</p></li>
<li><p><strong>nt_samples_batch_size</strong> – The number of the <cite>nt_samples</cite>
that will be processed together. With the help
of this parameter we can avoid out of memory situation and
reduce the number of randomly generated examples per sample
in each batch.
Default: None if <cite>nt_samples_batch_size</cite> is not provided. In
this case all <cite>nt_samples</cite> will be processed together.</p></li>
<li><p><strong>stdevs</strong> – The standard deviation
of gaussian noise with zero mean that is added to each
input in the batch. If <cite>stdevs</cite> is a single float value
then that same value is used for all inputs. If it is
a tuple, then it must have the same length as the inputs
tuple. In this case, each stdev value in the stdevs tuple
corresponds to the input with the same index in the inputs
tuple.
Default: <cite>1.0</cite> if <cite>stdevs</cite> is not provided.</p></li>
<li><p><strong>draw_baseline_from_distrib</strong> – Indicates whether to
randomly draw baseline samples from the <cite>baselines</cite>
distribution provided as an input tensor.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Attribution with respect to each input feature. attributions
will always be the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>RuntimeError</strong> – if attribution has shape (0).</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.noise_tunnel.BaseNoiseTunnelCVExplainer.create_explainer">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">create_explainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">NoiseTunnel</span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/noise_tunnel.html#BaseNoiseTunnelCVExplainer.create_explainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.noise_tunnel.BaseNoiseTunnelCVExplainer.create_explainer" title="Permalink to this definition"></a></dt>
<dd><p>Create explainer object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> – The forward function of the model or any
modification of it.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Explainer object.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.noise_tunnel.LayerNoiseTunnelCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.noise_tunnel.</span></span><span class="sig-name descname"><span class="pre">LayerNoiseTunnelCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/noise_tunnel.html#LayerNoiseTunnelCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.noise_tunnel.LayerNoiseTunnelCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#foxai.explainer.computer_vision.algorithm.noise_tunnel.BaseNoiseTunnelCVExplainer" title="foxai.explainer.computer_vision.algorithm.noise_tunnel.BaseNoiseTunnelCVExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseNoiseTunnelCVExplainer</span></code></a></p>
<p>Layer Noise Tunnel algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.noise_tunnel.LayerNoiseTunnelCVExplainer.create_explainer">
<span class="sig-name descname"><span class="pre">create_explainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Module</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">NoiseTunnel</span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/noise_tunnel.html#LayerNoiseTunnelCVExplainer.create_explainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.noise_tunnel.LayerNoiseTunnelCVExplainer.create_explainer" title="Permalink to this definition"></a></dt>
<dd><p>Create explainer object.</p>
<p>Uses parameter <cite>layer</cite> from <cite>kwargs</cite>. If not provided function will call
<cite>get_last_conv_model_layer</cite> function to obtain last <cite>torch.nn.Conv2d</cite> layer
from provided model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>layer</strong> – Layer for which attributions are computed.
Output size of attribute matches this layer’s input or
output dimensions, depending on whether we attribute to
the inputs or outputs of the layer, corresponding to
attribution of each neuron in the input or output of
this layer.
Default: None</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Explainer object.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong> – if model does not contain conv layers.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.noise_tunnel.NoiseTunnelCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.noise_tunnel.</span></span><span class="sig-name descname"><span class="pre">NoiseTunnelCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/noise_tunnel.html#NoiseTunnelCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.noise_tunnel.NoiseTunnelCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#foxai.explainer.computer_vision.algorithm.noise_tunnel.BaseNoiseTunnelCVExplainer" title="foxai.explainer.computer_vision.algorithm.noise_tunnel.BaseNoiseTunnelCVExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseNoiseTunnelCVExplainer</span></code></a></p>
<p>Noise Tunnel algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.noise_tunnel.NoiseTunnelCVExplainer.create_explainer">
<span class="sig-name descname"><span class="pre">create_explainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">NoiseTunnel</span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/noise_tunnel.html#NoiseTunnelCVExplainer.create_explainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.noise_tunnel.NoiseTunnelCVExplainer.create_explainer" title="Permalink to this definition"></a></dt>
<dd><p>Create explainer object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> – The forward function of the model or any
modification of it.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Explainer object.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-foxai.explainer.computer_vision.algorithm.occlusion">
<span id="foxai-explainer-computer-vision-algorithm-occlusion-module"></span><h2>foxai.explainer.computer_vision.algorithm.occlusion module<a class="headerlink" href="#module-foxai.explainer.computer_vision.algorithm.occlusion" title="Permalink to this heading"></a></h2>
<p>File with Occulusion algorithm explainer classes.</p>
<p>Based on <a class="reference external" href="https://github.com/pytorch/captum/blob/master/captum/attr/_core/occlusion.py">https://github.com/pytorch/captum/blob/master/captum/attr/_core/occlusion.py</a>.</p>
<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.occlusion.OcclusionCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.occlusion.</span></span><span class="sig-name descname"><span class="pre">OcclusionCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/occlusion.html#OcclusionCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.occlusion.OcclusionCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="foxai.explainer.html#foxai.explainer.base_explainer.Explainer" title="foxai.explainer.base_explainer.Explainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Explainer</span></code></a></p>
<p>Occlusion algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.occlusion.OcclusionCVExplainer.calculate_features">
<span class="sig-name descname"><span class="pre">calculate_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_label_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sliding_window_shapes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">(1,</span> <span class="pre">1,</span> <span class="pre">1)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">perturbations_per_eval</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/occlusion.html#OcclusionCVExplainer.calculate_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.occlusion.OcclusionCVExplainer.calculate_features" title="Permalink to this definition"></a></dt>
<dd><p>Generate model’s attributes with Occlusion algorithm explainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>input_data</strong> – Input for which occlusion
attributions are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.</p></li>
<li><p><strong>pred_label_idx</strong> – <p>Output indices for
which difference is computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>a single integer or a tensor containing a single</dt><dd><p>integer, which is applied to all input examples</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>a list of integers or a 1D tensor, with length matching</dt><dd><p>the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>A single tuple, which contains #output_dims - 1</dt><dd><p>elements. This target index is applied to all examples.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>A list of tuples with length equal to the number of</dt><dd><p>examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><strong>sliding_window_shapes</strong> – Shape of patch
(hyperrectangle) to occlude each input. For a single
input tensor, this must be a tuple of length equal to the
number of dimensions of the input tensor - 1, defining
the dimensions of the patch. If the input tensor is 1-d,
this should be an empty tuple.
Default: (1, 1, 1)</p></li>
<li><p><strong>strides</strong> – This defines the step by which the occlusion hyperrectangle
should be shifted by in each direction for each iteration.
For a single tensor input, this can be either a single
integer, which is used as the step size in each direction,
or a tuple of integers matching the number of dimensions
in the occlusion shape, defining the step size in the
corresponding dimension.
To ensure that all inputs are covered by at least one
sliding window, the stride for any dimension must be
&lt;= the corresponding sliding window dimension if the
sliding window dimension is less than the input
dimension.
If None is provided, a stride of 1 is used for each
dimension of each input tensor.
Default: None</p></li>
<li><p><strong>baselines</strong> – <p>Baselines define reference value which replaces each
feature when occluded.
Baselines can be provided as:</p>
<ul>
<li><dl class="simple">
<dt>a single tensor, if inputs is a single tensor, with</dt><dd><p>exactly the same dimensions as inputs or
broadcastable to match the dimensions of inputs</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>a single scalar, if inputs is a single tensor, which will</dt><dd><p>be broadcasted for each input value in input tensor.</p>
</dd>
</dl>
</li>
</ul>
<p>In the cases when <cite>baselines</cite> is not provided, we internally
use zero scalar corresponding to each input tensor.
Default: None</p>
</p></li>
<li><p><strong>additional_forward_args</strong> – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
For a tensor, the first dimension of the tensor must
correspond to the number of examples. For all other types,
the given argument is used for all forward evaluations.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><strong>perturbations_per_eval</strong> – Allows multiple occlusions
to be included in one batch (one call to forward_fn).
By default, perturbations_per_eval is 1, so each occlusion
is processed individually.
Each forward pass will contain a maximum of
perturbations_per_eval * #examples samples.
For DataParallel models, each batch is split among the
available devices, so evaluations on each available
device contain at most
(perturbations_per_eval * #examples) / num_devices
samples.
Default: 1</p></li>
<li><p><strong>show_progress</strong> – Displays the progress of computation.
It will try to use tqdm if available for advanced features
(e.g. time estimation). Otherwise, it will fallback to
a simple output of progress.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The attributions with respect to each input feature.
Attributions will always be
the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>RuntimeError</strong> – if attribution has shape (0).</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-foxai.explainer.computer_vision.algorithm.saliency">
<span id="foxai-explainer-computer-vision-algorithm-saliency-module"></span><h2>foxai.explainer.computer_vision.algorithm.saliency module<a class="headerlink" href="#module-foxai.explainer.computer_vision.algorithm.saliency" title="Permalink to this heading"></a></h2>
<p>File with Saliency algorithm explainer classes.</p>
<p>Based on <a class="reference external" href="https://github.com/pytorch/captum/blob/master/captum/attr/_core/saliency.py">https://github.com/pytorch/captum/blob/master/captum/attr/_core/saliency.py</a>.</p>
<dl class="py class">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.saliency.SaliencyCVExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foxai.explainer.computer_vision.algorithm.saliency.</span></span><span class="sig-name descname"><span class="pre">SaliencyCVExplainer</span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/saliency.html#SaliencyCVExplainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.saliency.SaliencyCVExplainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="foxai.explainer.html#foxai.explainer.base_explainer.Explainer" title="foxai.explainer.base_explainer.Explainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Explainer</span></code></a></p>
<p>Saliency algorithm explainer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="foxai.explainer.computer_vision.algorithm.saliency.SaliencyCVExplainer.calculate_features">
<span class="sig-name descname"><span class="pre">calculate_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_label_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">abs_value</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/foxai/explainer/computer_vision/algorithm/saliency.html#SaliencyCVExplainer.calculate_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foxai.explainer.computer_vision.algorithm.saliency.SaliencyCVExplainer.calculate_features" title="Permalink to this definition"></a></dt>
<dd><p>Generate model’s attributes with Saliency algorithm explainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The forward function of the model or any
modification of it.</p></li>
<li><p><strong>input_data</strong> – Input for which saliency
is computed. If forward_func takes a single tensor
as input, a single input tensor should be provided.</p></li>
<li><p><strong>pred_label_idx</strong> – <p>Output indices for
which gradients are computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>a single integer or a tensor containing a single</dt><dd><p>integer, which is applied to all input examples</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>a list of integers or a 1D tensor, with length matching</dt><dd><p>the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><dl class="simple">
<dt>A single tuple, which contains #output_dims - 1</dt><dd><p>elements. This target index is applied to all examples.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>A list of tuples with length equal to the number of</dt><dd><p>examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p>
</dd>
</dl>
</li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><strong>abs_value</strong> – Returns absolute value of gradients if set
to True, otherwise returns the (signed) gradients if
False.
Default: True</p></li>
<li><p><strong>additional_forward_args</strong> – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The gradients with respect to each input feature.
Attributions will always be
the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>RuntimeError</strong> – if attribution has shape (0).</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-foxai.explainer.computer_vision.algorithm">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-foxai.explainer.computer_vision.algorithm" title="Permalink to this heading"></a></h2>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="foxai.explainer.computer_vision.html" class="btn btn-neutral float-left" title="foxai.explainer.computer_vision package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="foxai.explainer.computer_vision.object_detection.html" class="btn btn-neutral float-right" title="foxai.explainer.computer_vision.object_detection package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, ReasonField Lab.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>